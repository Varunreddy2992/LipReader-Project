# Lip Reading using Deep Learning

## Overview
This project aims to develop a deep learning model for lip reading using Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Long Short-Term Memory (LSTM) cells. Lip reading, also known as automatic speech recognition from lip movements, plays a crucial role in enhancing communication accessibility for individuals with hearing impairments and in noisy environments.

## Project Structure
- `data/`: Contains the dataset used for training and evaluation.
- `models/`: Stores the trained models and checkpoints.
- `notebooks/`: Jupyter notebooks for data exploration, model development, and evaluation.
- `src/`: Source code for data preprocessing, model training, and inference.

## Requirements
- Python (>=3.6)
- TensorFlow (>=2.0)
- OpenCV (>=4.0)
- NumPy (>=1.16)
- Matplotlib (>=3.0)
- ImageIO (>=2.5)

## Usage
1. Clone the repository:
2. Install the required dependencies
3. 3. Prepare the dataset:
- Place the dataset in the `data/` directory.
- Preprocess the video data using the provided scripts.
4. Train the model:
- Run the training script to train the deep learning model on the dataset.
5. Evaluate the model:
- Use the trained model to make predictions on test data and evaluate performance metrics.
6. Fine-tune and experiment with different architectures, hyperparameters, and optimization strategies to improve model performance.

## Credits
This project was developed by Darshan R as part of University Final Year Project.
